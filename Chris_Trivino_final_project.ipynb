{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chris_Trivino_final_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOB1LcIfnlttgTTYLpCiKuP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ctrivino1/ML_class_final/blob/main/Chris_Trivino_final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbZzz2oy3b25"
      },
      "source": [
        "Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy3PmcrjyQtb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22602261-0fe6-4745-f6ee-db21241d1e6c"
      },
      "source": [
        "!pip install pyforest\n",
        "!pip install git+https://github.com/keras-team/keras-preprocessing.git\n",
        "!pip install keras-rectified-adam\n",
        "!pip install tensorflow_addons\n",
        "import tensorflow_addons as tfa\n",
        "from keras_radam import RAdam\n",
        "import pyforest\n",
        "import shutil, os\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from keras_radam import RAdam\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyforest in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Collecting git+https://github.com/keras-team/keras-preprocessing.git\n",
            "  Cloning https://github.com/keras-team/keras-preprocessing.git to /tmp/pip-req-build-204ritti\n",
            "  Running command git clone -q https://github.com/keras-team/keras-preprocessing.git /tmp/pip-req-build-204ritti\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras-Preprocessing==1.1.2) (1.19.5)\n",
            "Requirement already satisfied: keras-rectified-adam in /usr/local/lib/python3.7/dist-packages (0.19.0)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.7/dist-packages (from keras-rectified-adam) (2.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-rectified-adam) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gu_lX-Sc3bcP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "010f44f9-9c11-47da-9137-07d406c3829d"
      },
      "source": [
        "!git clone https://github.com/ctrivino1/ML_class_final.git\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ML_class_final' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSFRurgaSC4Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "67a5c75a-8d36-4fe6-a4fe-f4b6bb22cbd8"
      },
      "source": [
        "training_dir = \"/content/ML_class_final/train_imgs_1\"\n",
        "test_dir = \"/content/ML_class_final/test_imgs_1\"\n",
        "df=pd.read_csv(\"/content/ML_class_final/train_1.csv\")\n",
        "df.label = df.label.astype(str)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssQFogS1TDLi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b96e552-845a-4cad-a108-b1b36657e80b"
      },
      "source": [
        "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=.2,zoom_range=.2,horizontal_flip=True,width_shift_range=0.05,height_shift_range=0.05,validation_split=.2,)\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_dataframe(dataframe=df, \n",
        "                                         directory=training_dir, \n",
        "                                         x_col=\"image_id\", \n",
        "                                         y_col=\"label\", \n",
        "                                         class_mode=\"categorical\", \n",
        "                                         target_size=(224,224), \n",
        "                                         batch_size=64,\n",
        "                                         subset=\"training\",\n",
        "                                         seed=69,\n",
        "                                         )\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 13694 validated image filenames belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yizwNBTljJvK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bfda69e-6b4b-4326-ac05-1cac45a0d942"
      },
      "source": [
        "\n",
        "valid_generator = train_datagen.flow_from_dataframe(dataframe=df, \n",
        "                                         directory=training_dir, \n",
        "                                         x_col=\"image_id\", \n",
        "                                         y_col=\"label\", \n",
        "                                         class_mode=\"categorical\", \n",
        "                                         target_size=(224,224), \n",
        "                                         batch_size=64,\n",
        "                                         subset=\"validation\",\n",
        "                                         seed=69)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3423 validated image filenames belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jv4cXwEOUL6_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df2204ff-5330-4824-f6d9-c48d44800e78"
      },
      "source": [
        "\n",
        "resnet50 = tf.keras.applications.ResNet50(\n",
        "    include_top=False, weights='imagenet', input_tensor=None,\n",
        "    input_shape=(224,224,3), pooling=\"max\"\n",
        ")\n",
        "\n",
        "\n",
        "vgg16 = tf.keras.applications.VGG16(\n",
        "    include_top=False, weights='imagenet', input_tensor=None,\n",
        "    input_shape=(224,224,3), pooling=\"max\"\n",
        ")\n",
        "# Freeze the pretrained CNN's\n",
        "resnet50.trainable = False\n",
        "vgg16.trainable = False\n",
        "\n",
        "# optimizers\n",
        "radam = tfa.optimizers.RectifiedAdam(learning_rate=1e-3)\n",
        "\n",
        "# Adds ResNet50 into a model with a output layers with 5 classifaction nodes\n",
        "model = keras.Sequential([vgg16,\n",
        "    tf.keras.layers.Dense(units=256, activation='LeakyReLU'),\n",
        "    tf.keras.layers.Dense(units=256, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(units=256, activation='LeakyReLU'),\n",
        "    tf.keras.layers.Dense(5,activation=\"softmax\") # number of perceptrons\n",
        "])\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "optimizer=radam, metrics=['acc'])\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "model.fit(train_generator,\n",
        "          validation_data = valid_generator,\n",
        "          steps_per_epoch = STEP_SIZE_TRAIN,\n",
        "          validation_steps = STEP_SIZE_VALID,\n",
        "          epochs=15)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "213/213 [==============================] - 272s 1s/step - loss: 1.1225 - acc: 0.5964 - val_loss: 0.9813 - val_acc: 0.6518\n",
            "Epoch 2/15\n",
            "213/213 [==============================] - 259s 1s/step - loss: 0.9307 - acc: 0.6596 - val_loss: 0.9391 - val_acc: 0.6704\n",
            "Epoch 3/15\n",
            "213/213 [==============================] - 260s 1s/step - loss: 0.8951 - acc: 0.6689 - val_loss: 0.9540 - val_acc: 0.6651\n",
            "Epoch 4/15\n",
            "213/213 [==============================] - 260s 1s/step - loss: 0.8812 - acc: 0.6789 - val_loss: 0.8636 - val_acc: 0.6837\n",
            "Epoch 5/15\n",
            "213/213 [==============================] - 260s 1s/step - loss: 0.8584 - acc: 0.6827 - val_loss: 0.8566 - val_acc: 0.6843\n",
            "Epoch 6/15\n",
            "213/213 [==============================] - 260s 1s/step - loss: 0.8542 - acc: 0.6886 - val_loss: 0.9539 - val_acc: 0.6300\n",
            "Epoch 7/15\n",
            "213/213 [==============================] - 260s 1s/step - loss: 0.8457 - acc: 0.6884 - val_loss: 0.8694 - val_acc: 0.6810\n",
            "Epoch 8/15\n",
            "213/213 [==============================] - 259s 1s/step - loss: 0.8366 - acc: 0.6883 - val_loss: 0.8576 - val_acc: 0.6801\n",
            "Epoch 9/15\n",
            "213/213 [==============================] - 260s 1s/step - loss: 0.8293 - acc: 0.6943 - val_loss: 0.9185 - val_acc: 0.6704\n",
            "Epoch 10/15\n",
            "213/213 [==============================] - 260s 1s/step - loss: 0.8252 - acc: 0.6975 - val_loss: 0.8506 - val_acc: 0.6899\n",
            "Epoch 11/15\n",
            "213/213 [==============================] - 261s 1s/step - loss: 0.8189 - acc: 0.6982 - val_loss: 0.8440 - val_acc: 0.6816\n",
            "Epoch 12/15\n",
            "213/213 [==============================] - 260s 1s/step - loss: 0.8039 - acc: 0.7042 - val_loss: 0.8230 - val_acc: 0.6896\n",
            "Epoch 13/15\n",
            "213/213 [==============================] - 259s 1s/step - loss: 0.8110 - acc: 0.6994 - val_loss: 0.8738 - val_acc: 0.6934\n",
            "Epoch 14/15\n",
            "213/213 [==============================] - 259s 1s/step - loss: 0.8085 - acc: 0.7029 - val_loss: 0.8665 - val_acc: 0.6781\n",
            "Epoch 15/15\n",
            "213/213 [==============================] - 260s 1s/step - loss: 0.8079 - acc: 0.7019 - val_loss: 0.8256 - val_acc: 0.7022\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f863034c790>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vRfJ1x5EsnH1",
        "outputId": "5cbce761-a122-41ce-8b46-7a41126483a8"
      },
      "source": [
        "#downloading the model as a zipfile\n",
        "\n",
        "import shutil\n",
        "shutil.make_archive('70_perc_model', 'zip', '70_perc_model')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/70_perc_model.zip'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgyrhBMT-pVR"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "\n",
        "def predict_an_image(model, file_path):\n",
        "  # Load the image\n",
        "  img = keras.preprocessing.image.load_img(file_path, target_size=(224, 224))\n",
        "  # Get the image into the shape we need for our network\n",
        "  img_array = keras.preprocessing.image.img_to_array(img)\n",
        "  img_array = tf.expand_dims(img_array, 0) \n",
        "  # Predict the class\n",
        "  predictions = model.predict(img_array)\n",
        "  score = tf.nn.softmax(predictions[0])\n",
        "  return np.argmax(score)\n",
        "# Loop through all images in our test directory and make\n",
        "# a prediction\n",
        "testdir = pathlib.Path('/content/ML_class_final/test_imgs_1')\n",
        "image_paths = (testdir.glob('*.jpg'))\n",
        "ip = []\n",
        "pred = []\n",
        "for image_path in image_paths:\n",
        "  prediction = predict_an_image(model, str(image_path))\n",
        "  ip.append(image_path)\n",
        "  pred.append(prediction)\n",
        "  #print(image_path, prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Td_-2yjQAxyC",
        "outputId": "ab2c4a05-0ec0-40d9-d034-f3f37bb9f926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "im_path = np.array(ip)\n",
        "preds = np.array(pred)\n",
        "df = pd.DataFrame({'Filename':im_path, 'class':preds})\n",
        "df.head()\n"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import statistics\\nimport bokeh\\nimport nltk\\nfrom sklearn.feature_extraction.text import CountVectorizer\\nfrom statsmodels.tsa.arima_model import ARIMA\\nimport altair as alt\\nfrom sklearn.model_selection import cross_val_score\\nimport fastai\\nimport pandas as pd\\nfrom scipy import stats\\nimport skimage\\nfrom sklearn.model_selection import train_test_split\\nimport tqdm\\nimport sys\\nimport pickle\\nimport statsmodels.api as sm\\nimport lightgbm as lgb\\nimport torch\\nimport fbprophet\\nimport plotly as py\\nimport numpy as np\\nimport matplotlib as mpl\\nimport imutils\\nfrom sklearn import svm\\nimport textblob\\nimport pydot\\nimport spacy\\nimport seaborn as sns\\nfrom scipy import signal as sg\\nimport matplotlib.pyplot as plt\\nimport sklearn\\nfrom sklearn import metrics\\nimport re\\nfrom openpyxl import load_workbook\\nimport cv2\\nimport plotly.express as px'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/ML_class_final/test_imgs_1/3546777867...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/ML_class_final/test_imgs_1/608792631.jpg</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/ML_class_final/test_imgs_1/1154243459...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/ML_class_final/test_imgs_1/387772759.jpg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/ML_class_final/test_imgs_1/600610735.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Filename  class\n",
              "0  /content/ML_class_final/test_imgs_1/3546777867...      1\n",
              "1  /content/ML_class_final/test_imgs_1/608792631.jpg      2\n",
              "2  /content/ML_class_final/test_imgs_1/1154243459...      0\n",
              "3  /content/ML_class_final/test_imgs_1/387772759.jpg      1\n",
              "4  /content/ML_class_final/test_imgs_1/600610735.jpg      4"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHWjot1JDFxP",
        "outputId": "41292785-adc6-4cec-e1f4-b6acb170ebc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "## save the new dataframe to csv\n",
        "\n",
        "df.to_csv('predictions.csv')\n",
        "files.download('predictions.csv')"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_5fa67722-9c3a-44ed-9abf-b5e5db6e9f17\", \"predictions.csv\", 245989)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Eea7H6EEvJP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}